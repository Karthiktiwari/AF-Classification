{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9e31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45045f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../../Data/dataset/'\n",
    "files = os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8eff2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals = np.empty((1,200))\n",
    "# labels = np.empty(1)\n",
    "# for csvfile in tqdm(files):\n",
    "#     df = pd.read_csv(os.path.join(root, csvfile))\n",
    "# #     print(df.head())\n",
    "#     label = np.expand_dims(np.array(df['label']), axis = 1)\n",
    "#     sigs = np.array(df.drop(['label'], axis = 1))\n",
    "# #     print(label.shape, sigs.shape)\n",
    "#     signals = np.vstack((signals, sigs))\n",
    "#     labels = np.vstack((labels, label))\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7877ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1586000, 1) (1586000, 200)\n"
     ]
    }
   ],
   "source": [
    "# signals = np.array(signals)\n",
    "# labels = np.array(labels)\n",
    "signals = np.load(\"../../../Data/AFData/signals.npy\")\n",
    "labels = np.load(\"../../../Data/AFData/labels.npy\")\n",
    "print(labels.shape, signals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819dc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(signals[1:], labels[1:],\n",
    "                                                    test_size=0.2, stratify=labels[1:],\n",
    "                                                    random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f479c421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([531936]), array([1054064]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1), sum(labels==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d193bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del signals, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6280d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../../../Data/AFData/signals.npy'):\n",
    "    np.save('/home/karthiktiwari/Data/AFData/signals.npy', signals)\n",
    "    np.save('/home/karthiktiwari/Data/AFData/labels.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69083e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = torch.Tensor(\n",
    "            self.signals[idx]\n",
    "        )\n",
    "        label = self.labels[idx]\n",
    "        return {'signal': signal, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f10fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AFDataset(X_train, y_train)\n",
    "test_data = AFDataset(X_test, y_test)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=128, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cecd5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa89c6b3850>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_data[1000]['signal'].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0120188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data[0]['signal'].numpy())\n",
    "# print(labels[1])\n",
    "# print(np.unique(labels[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875c10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AFModel, self).__init__()\n",
    "        # self.attn = nn.MultiheadAttention(\n",
    "        #     embed_dim=128, num_heads=1, batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(1, 32, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(64, 64, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(25600, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        # x, _ = self.attn(x, x, x)\n",
    "        x = self.drop(x)\n",
    "        b, _, _ = x.shape\n",
    "        x = x.reshape(b, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be74b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AFConvNet, self).__init__()\n",
    "        # self.attn = nn.MultiheadAttention(\n",
    "        #     embed_dim=64, num_heads=1, batch_first=True)\n",
    "        self.conv1 = nn.Conv1d(1, 32, 16, padding=16, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 8, padding=16, stride=2)\n",
    "        self.fc1 = nn.Linear(4288, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        # x, _ = self.attn(x, x, x)\n",
    "        x = self.drop(x)\n",
    "        b, _, _ = x.shape\n",
    "        x = x.reshape(b, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4444db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFConvLSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AFConvLSTMNet, self).__init__()\n",
    "        self.convBlock = AFConvNet()\n",
    "        self.LSTMBlock = AFModel()\n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_copy = x.clone()\n",
    "        x = self.convBlock(x)\n",
    "        x_copy = self.LSTMBlock(x_copy)\n",
    "        x = torch.hstack((x, x_copy))\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176da032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, opt, loss_fn, device, size, threshold=0.5):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for data in tqdm(loader):\n",
    "        X = data['signal'].float().to(device)\n",
    "        y = data['label'].float().to(device)\n",
    "\n",
    "        output = model(X)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        preds = output.squeeze(dim=1)\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = torch.tensor(\n",
    "            [1 if x > threshold else 0 for x in preds]).to(device)\n",
    "\n",
    "        gt = y.squeeze(dim=1)\n",
    "\n",
    "        count += (preds == gt).sum()\n",
    "\n",
    "    return total_loss, count / size, output\n",
    "\n",
    "\n",
    "def val_epoch(model, loader, loss_fn, device, size, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader):\n",
    "            X = data['signal'].float().to(device)\n",
    "            y = data['label'].float().to(device)\n",
    "\n",
    "            output = model(X)\n",
    "\n",
    "            loss = loss_fn(output, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = output.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds)\n",
    "            preds = torch.tensor(\n",
    "                [1 if x > threshold else 0 for x in preds]).to(device)\n",
    "\n",
    "            gt = y.squeeze(dim=1)\n",
    "\n",
    "            count += (preds == gt).sum()\n",
    "\n",
    "    return total_loss, count / size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9698d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "# model = AFModel().to(device)\n",
    "model = AFConvLSTMNet().to(device)\n",
    "optimiser = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=3, gamma=0.7)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c0c9f31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9913/9913 [10:38<00:00, 15.51it/s]\n",
      "100%|██████████| 2479/2479 [00:47<00:00, 51.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Accuaracy: 0.9745704531669617 Train Loss: 647.4333880324848\n",
      "Val Accuaracy: 0.9751355648040771 Val Loss: 156.35274312272668\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_acc, op = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(y_train),\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = val_epoch(\n",
    "        model,\n",
    "        test_dataloader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(y_test)\n",
    "    )\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    print(f'Train Accuaracy: {train_acc} Train Loss: {train_loss}')\n",
    "    print(f'Val Accuaracy: {val_acc} Val Loss: {val_loss}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dbf7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input()\n",
    "torch.save(model.state_dict(), '{}.pth'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aadf85fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AFConvLSTMNet:\n\tMissing key(s) in state_dict: \"LSTMBlock.lstm1.weight_ih_l0_reverse\", \"LSTMBlock.lstm1.weight_hh_l0_reverse\", \"LSTMBlock.lstm1.bias_ih_l0_reverse\", \"LSTMBlock.lstm1.bias_hh_l0_reverse\", \"LSTMBlock.lstm2.weight_ih_l0_reverse\", \"LSTMBlock.lstm2.weight_hh_l0_reverse\", \"LSTMBlock.lstm2.bias_ih_l0_reverse\", \"LSTMBlock.lstm2.bias_hh_l0_reverse\". \n\tsize mismatch for LSTMBlock.attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for LSTMBlock.attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for LSTMBlock.attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for LSTMBlock.attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for LSTMBlock.lstm2.weight_ih_l0: copying a param with shape torch.Size([256, 32]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for LSTMBlock.fc1.weight: copying a param with shape torch.Size([512, 12800]) from checkpoint, the shape in current model is torch.Size([512, 25600]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/karthiktiwari/Documents/Projects/AF Classification/Modelling.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/karthiktiwari/Documents/Projects/AF%20Classification/Modelling.ipynb#ch0000019?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mAttnBasedLSTM.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1491'>1492</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1492'>1493</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1493'>1494</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1495'>1496</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1496'>1497</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1497'>1498</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/karthiktiwari/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1498'>1499</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AFConvLSTMNet:\n\tMissing key(s) in state_dict: \"LSTMBlock.lstm1.weight_ih_l0_reverse\", \"LSTMBlock.lstm1.weight_hh_l0_reverse\", \"LSTMBlock.lstm1.bias_ih_l0_reverse\", \"LSTMBlock.lstm1.bias_hh_l0_reverse\", \"LSTMBlock.lstm2.weight_ih_l0_reverse\", \"LSTMBlock.lstm2.weight_hh_l0_reverse\", \"LSTMBlock.lstm2.bias_ih_l0_reverse\", \"LSTMBlock.lstm2.bias_hh_l0_reverse\". \n\tsize mismatch for LSTMBlock.attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for LSTMBlock.attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for LSTMBlock.attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for LSTMBlock.attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for LSTMBlock.lstm2.weight_ih_l0: copying a param with shape torch.Size([256, 32]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for LSTMBlock.fc1.weight: copying a param with shape torch.Size([512, 12800]) from checkpoint, the shape in current model is torch.Size([512, 25600])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('AttnBasedLSTM.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d47da23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2479/2479 [00:46<00:00, 53.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is 97.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "threshold = 0.5\n",
    "count = 0\n",
    "gts = []\n",
    "model_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader):\n",
    "        X = data['signal'].float().to(device)\n",
    "        y = data['label'].float().to(device)\n",
    "\n",
    "        output = model(X)\n",
    "        preds = output.squeeze(dim=1)\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = torch.tensor(\n",
    "            [1 if x > threshold else 0 for x in preds]).to(device)\n",
    "        model_preds.extend(preds.detach().cpu().numpy())\n",
    "        gts.extend(y.detach().cpu().numpy())\n",
    "        gt = y.squeeze(dim=1)\n",
    "\n",
    "        count += (preds == gt).sum()\n",
    "\n",
    "print(\"Accuracy on Test Data is {0:.4g}%\".format(\n",
    "    (count.item()*100)/len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "931020f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99    210813\n",
      "         1.0       0.98      0.97      0.98    106387\n",
      "\n",
      "    accuracy                           0.98    317200\n",
      "   macro avg       0.98      0.98      0.98    317200\n",
      "weighted avg       0.98      0.98      0.98    317200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(gts, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1100247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(np.array(model_preds), np.array(gts))\n",
    "# precision_score = precision_score(np.array(model_preds), np.array(gts))\n",
    "# print('precision_score :\\n',precision_score)\n",
    "# recall_score = recall_score(np.array(model_preds), np.array(gts))\n",
    "# print('recall_score :\\n',recall_score)\n",
    "# f1_score = f1_score(np.array(model_preds), np.array(gts))\n",
    "# print('f1_score :\\n',f1_score)\n",
    "# tp, fp, tn, fn = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "# print(\"Confusion Matrix: TP {}, FP {}, TN {}, FN {}\".format(tp,fp,tn,fn))\n",
    "\n",
    "# total = sum(sum(cm))\n",
    "# # from confusion matrix calculate accuracy\n",
    "# accuracy = (cm[0, 0]+cm[1, 1])/total\n",
    "# print('Accuracy : ', accuracy)\n",
    "\n",
    "# sensitivity = cm[0, 0]/(cm[0, 0]+cm[0, 1])\n",
    "# print('Sensitivity : ', sensitivity)\n",
    "\n",
    "# specificity = cm[1, 1]/(cm[1, 0]+cm[1, 1])\n",
    "# print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4ac87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
